{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tech_test_data.csv\")\n",
    "df = pd.concat([df.message, df.case_type], axis=1)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_non_ascii(text):\n",
    "    return ''.join(i for i in text if ord(i) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.message = df.message.apply(clean_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = tts(df.message, df.case_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    feature, \n",
    "    label, \n",
    "    model_name, \n",
    "    logreg_jobs=1, \n",
    "    logreg_c=1e5, \n",
    "    lsvm_loss='hinge', \n",
    "    lsvm_penalty='l2', \n",
    "    lsvm_alpha=1e-3, \n",
    "    lsvm_random_state=42, \n",
    "    lsvm_max_iter=5, \n",
    "    lsvm_tol=None\n",
    "):\n",
    "    classifier = None\n",
    "    if model_name == 'naive bayes':\n",
    "        classifier = MultinomialNB()\n",
    "    elif model_name == 'logistic regression':\n",
    "        classifier = LogisticRegression(n_jobs=logreg_jobs, C=logreg_c)\n",
    "    elif model_name == 'lsvm':\n",
    "        classifier = SGDClassifier(\n",
    "            loss=lsvm_loss, \n",
    "            penalty=lsvm_penalty, \n",
    "            alpha=lsvm_alpha, \n",
    "            random_state=lsvm_random_state, \n",
    "            max_iter=lsvm_max_iter, \n",
    "            tol=lsvm_tol\n",
    "        )\n",
    "    model = Pipeline([\n",
    "        ('vectorizer', CountVectorizer()),\n",
    "        ('transformer', TfidfTransformer()),\n",
    "        ('classifier', classifier),\n",
    "    ]).fit(feature, label)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = get_model(x_train, y_train, 'naive bayes')\n",
    "logreg_classifier = get_model(x_train, y_train, 'logistic regression')\n",
    "lsvm_classifier = get_model(x_train, y_train, 'lsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_y_pred = nb_classifier.predict(x_test)\n",
    "logreg_y_pred = logreg_classifier.predict(x_test)\n",
    "lsvm_y_pred = lsvm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Accuracies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Naive Bayes': 0.6818181818181818,\n",
       " 'Logitic Regression': 0.8181818181818182,\n",
       " 'Support Vector Machine': 0.7727272727272727}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = {\n",
    "    'Naive Bayes': accuracy_score(nb_y_pred, y_test),\n",
    "    'Logitic Regression': accuracy_score(logreg_y_pred, y_test),\n",
    "    'Support Vector Machine': accuracy_score(lsvm_y_pred, y_test)\n",
    "}\n",
    "print('Models Accuracies')\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Reports\n",
      "\n",
      "Naive Bayes\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "cancel_order       0.82      0.64      0.72        14\n",
      "order_status       0.55      0.75      0.63         8\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        22\n",
      "   macro avg       0.68      0.70      0.68        22\n",
      "weighted avg       0.72      0.68      0.69        22\n",
      "\n",
      "\n",
      "Logitic Regression\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "cancel_order       0.92      0.79      0.85        14\n",
      "order_status       0.70      0.88      0.78         8\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        22\n",
      "   macro avg       0.81      0.83      0.81        22\n",
      "weighted avg       0.84      0.82      0.82        22\n",
      "\n",
      "\n",
      "Support Vector Machine\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "cancel_order       0.91      0.71      0.80        14\n",
      "order_status       0.64      0.88      0.74         8\n",
      "\n",
      "   micro avg       0.77      0.77      0.77        22\n",
      "   macro avg       0.77      0.79      0.77        22\n",
      "weighted avg       0.81      0.77      0.78        22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = df['case_type'].unique()\n",
    "reports = {\n",
    "    'Naive Bayes': classification_report(y_test, nb_y_pred, target_names=target),\n",
    "    'Logitic Regression': classification_report(y_test, logreg_y_pred, target_names=target),\n",
    "    'Support Vector Machine': classification_report(y_test, lsvm_y_pred, target_names=target)\n",
    "}\n",
    "print('Models Reports\\n')\n",
    "for name, report in reports.items():\n",
    "    print(f'{name}\\n-----------------------------------------------------')\n",
    "    print(f'{report}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88af651b55ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GoogleNews-vectors-negative300.bin.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: pip3: not found\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
